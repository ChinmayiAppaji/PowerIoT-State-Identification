{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFxeXCM5-g5S"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_files_path = '/content/gdrive/MyDrive/Data Files/Release Data'\n",
        "!ls '/content/gdrive/MyDrive/Data Files/Release Data'"
      ],
      "metadata": {
        "id": "cKO7Xmru_vlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Location = 'USA-2'\n",
        "harmonics_data = data_files_path + f'/Harmonics Data/{Location}/{Location}_harmonics.csv'\n",
        "power_data = data_files_path + f'/Power consumption data/{Location}/{Location}.csv'"
      ],
      "metadata": {
        "id": "_IJlbpFVMmEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import ceil\n",
        "import math\n",
        "import numpy as np\n",
        "import calendar\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import re\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "\n",
        "from numpy.lib.function_base import average\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import matplotlib.lines as mlines\n",
        "from sklearn import metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "calendar.setfirstweekday(6)"
      ],
      "metadata": {
        "id": "iKiZx5OQ_4bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(rc={'figure.figsize':(20,8)})\n",
        "\n",
        "palette = {\n",
        "    '0': list(sns.color_palette())[0],\n",
        "    '1': list(sns.color_palette())[1],\n",
        "    '2': list(sns.color_palette())[2],\n",
        "    '3': list(sns.color_palette())[3],\n",
        "    '4': list(sns.color_palette())[4],\n",
        "    '5': list(sns.color_palette())[5],\n",
        "}\n"
      ],
      "metadata": {
        "id": "loto5GF1b86R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_data( path ):\n",
        "\n",
        "    file_path = Path(path)\n",
        "    print(file_path)\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    df = df.rename(columns={'Unnamed: 0': 'datetime'})\n",
        "    df['datetime'] = pd.to_datetime(df['datetime']) \n",
        "    df = df.set_index('datetime')\n",
        "    df = df.tz_convert('US/Eastern')\n",
        "    df = df.resample('1min').mean()\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "zQNaNbM9AG83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_function(df , components):\n",
        "\n",
        "  if 'ActivePT' in df.columns:\n",
        "    feature_array = df.drop( ['ActivePT'], axis=1 ).values\n",
        "  else:\n",
        "    feature_array = df.values\n",
        "\n",
        "  pca = PCA(n_components=components)\n",
        "  principalComponents = pca.fit_transform(feature_array)\n",
        "  principalDf = pd.DataFrame(data = principalComponents, columns = ['components_'+str(i+1) for i in range(components) ] )\n",
        "  principalDf.index = df.index\n",
        "\n",
        "  return principalDf"
      ],
      "metadata": {
        "id": "KBkhFi4JxWM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_power = preprocessing_data(power_data)\n",
        "df_harmonics = preprocessing_data(harmonics_data)"
      ],
      "metadata": {
        "id": "RZ9wQVEx2RCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering the required features\n",
        "df_power = df_power[['ActivePT']]\n",
        "df_harmonics = df_harmonics[[ \"AI_HR3\", \"AI_HR5\", \"AI_HR7\", \"AI_HR9\", 'AI_HR11', 'AI_HR13', 'AI_HR15', 'AI_HR17', 'AI_HR19', 'AI_HR21', 'AI_HR23', 'AI_HR25', 'AI_HR27', 'AI_HR29', 'AI_HR31',\n",
        "                              \"BI_HR3\", \"BI_HR5\", \"BI_HR7\", \"BI_HR9\", 'BI_HR11', 'BI_HR13', 'BI_HR15', 'BI_HR17', 'BI_HR19', 'BI_HR21', 'BI_HR23', 'BI_HR25', 'BI_HR27', 'BI_HR29', 'BI_HR31', \n",
        "                              \"CI_HR3\", \"CI_HR5\", \"CI_HR7\", \"CI_HR9\", 'CI_HR11', 'CI_HR13', 'CI_HR15', 'CI_HR17', 'CI_HR19', 'CI_HR21', 'CI_HR23', 'CI_HR25', 'CI_HR27', 'CI_HR29', 'CI_HR31',\n",
        "                            ]]"
      ],
      "metadata": {
        "id": "7S_KA2z6N5zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = pd.merge( df_harmonics, df_power, left_index=True, right_index=True)\n",
        "round(df_merged.isna().sum().sum()/(len(df_merged)*len(df_merged.columns)),4)*100"
      ],
      "metadata": {
        "id": "mdc8OvT6pfHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Functions to replace nan values - Functions for Interpolation\n",
        "\n",
        "def search_past_dates( data, timestamp, col ):\n",
        "  # print('Searching for values in past dates to ',timestamp)\n",
        "  start_timestamp = data.index[0]\n",
        "  end_timestamp = timestamp - timedelta(days=1)\n",
        "\n",
        "  time_value = timestamp.strftime('%H:%M:%S')\n",
        "\n",
        "  start_date = start_timestamp.date()\n",
        "  end_date = end_timestamp.date()\n",
        "\n",
        "  if start_date > end_date:\n",
        "    return False\n",
        "\n",
        "  period = (end_date - start_date).days + 1\n",
        "\n",
        "  for dt in pd.date_range( start_date, periods = period )[::-1]:\n",
        "    timestamp_str = str(dt.date()) +' ' + str(time_value)\n",
        "    timestamp_var = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S' )\n",
        "\n",
        "    if timestamp_str < start_timestamp.strftime( '%Y-%m-%d %H:%M:%S' ):\n",
        "      break\n",
        "\n",
        "    if timestamp_var not in data.index:\n",
        "      continue\n",
        "\n",
        "    value = data.loc[timestamp_str][col]\n",
        "\n",
        "    if math.isnan( value ) == False:\n",
        "      return timestamp_str\n",
        "\n",
        "  return False\n",
        "\n",
        "\n",
        "def search_future_dates( data, timestamp, col ):\n",
        "  # print('Searching for values in future dates to ',timestamp)\n",
        "  start_timestamp = timestamp + timedelta(days=1)\n",
        "  end_timestamp = data.index[-1]\n",
        "\n",
        "  time_value = timestamp.strftime('%H:%M:%S')\n",
        "\n",
        "  start_date = start_timestamp.date()\n",
        "  end_date = end_timestamp.date()\n",
        "\n",
        "  if start_date > end_date:\n",
        "    return False\n",
        "\n",
        "  period = (end_date - start_date).days + 1\n",
        "\n",
        "  for dt in pd.date_range( start_date, periods = period ):\n",
        "    timestamp_str = str(dt.date()) +' ' + str(time_value)\n",
        "    timestamp_var = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S' )\n",
        "\n",
        "    if timestamp_str > end_timestamp.strftime( '%Y-%m-%d %H:%M:%S' ):\n",
        "      break\n",
        "\n",
        "    if timestamp_var not in data.index:\n",
        "      continue\n",
        "\n",
        "    value = data.loc[timestamp_str][col]\n",
        "\n",
        "    if math.isnan( value ) == False:\n",
        "      return timestamp_str\n",
        "\n",
        "  return False\n",
        "    \n",
        "# Fill the missing data in the dataframe - Interpolting the dataframe\n",
        "\n",
        "def interpolate_dataframe(df):\n",
        "  curr_month = 0\n",
        "  for idx in df.index:\n",
        "\n",
        "    if idx.date().month != curr_month:\n",
        "      curr_month = idx.date().month\n",
        "      # print(idx.date())\n",
        "\n",
        "    if df.loc[idx].isnull().values.any() == True:\n",
        "\n",
        "      if math.isnan( df.loc[idx]['ActivePT'] ) == False:\n",
        "        past_idx = search_past_dates( df, idx, 'AI_HR3' )\n",
        "        future_idx = search_future_dates( df, idx, 'AI_HR3' )\n",
        "\n",
        "        # print(idx, past_idx, future_idx)\n",
        "\n",
        "        if past_idx == False:\n",
        "          df.loc[idx, df.columns!='ActivePT'] = df.loc[future_idx, df.columns!='ActivePT']\n",
        "          continue\n",
        "\n",
        "        if future_idx == False:\n",
        "          df.loc[idx, df.columns!='ActivePT'] = df.loc[past_idx, df.columns!='ActivePT']\n",
        "          continue\n",
        "\n",
        "        df.loc[idx, df.columns!='ActivePT'] = (df.loc[past_idx, df.columns!='ActivePT'] + df.loc[future_idx, df.columns!='ActivePT'])/2\n",
        "\n",
        "      if math.isnan( df.loc[idx]['ActivePT'] ) == True:\n",
        "        past_idx = search_past_dates( df, idx, 'ActivePT' )\n",
        "        future_idx = search_future_dates( df, idx, 'ActivePT' )\n",
        "\n",
        "        # print(idx, past_idx, future_idx)\n",
        "\n",
        "        if past_idx == False:\n",
        "          df.loc[idx]['ActivePT'] = df.loc[future_idx]['ActivePT']\n",
        "          continue\n",
        "\n",
        "        if future_idx == False:\n",
        "          df.loc[idx]['ActivePT'] = df.loc[past_idx]['ActivePT']\n",
        "          continue\n",
        "\n",
        "        df.loc[idx] = (df.loc[past_idx] + df.loc[future_idx])/2\n",
        "\n",
        "  # if df.isnull().values.any():\n",
        "  #   df = df.fillna( df.mean() )\n",
        "\n",
        "  return df\n",
        "  # print( df.isnull().values.any())"
      ],
      "metadata": {
        "id": "Nzvp6er238AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged_filled = interpolate_dataframe(df_merged.copy())\n",
        "round(df_merged_filled.isna().sum().sum()/(len(df_merged_filled)*len(df_merged_filled.columns)),4)*100"
      ],
      "metadata": {
        "id": "ZOaLaKOrsTwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if df_merged_filled.isnull().values.any():\n",
        "  df_merged_filled = df_merged_filled.fillna( df_merged_filled.mean() )\n",
        "df_merged_filled.isnull().values.any(), round(df_merged_filled.isna().sum().sum()/(len(df_merged_filled)*len(df_merged_filled.columns)),4)*100"
      ],
      "metadata": {
        "id": "os5a4jN8RTsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.equals(df_merged_filled)"
      ],
      "metadata": {
        "id": "q7EQH3-IRaYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def cluster_kmeans(data, n_clusters, return_centers=False):\n",
        "\n",
        "  model = KMeans(n_clusters=n_clusters, random_state=100000).fit(data)\n",
        "  centers = model.cluster_centers_\n",
        "  X_labels = model.labels_\n",
        "\n",
        "  if return_centers == True:\n",
        "    return [str(i) for i in X_labels], centers\n",
        "  else:\n",
        "    return [str(i) for i in X_labels], model.inertia_"
      ],
      "metadata": {
        "id": "LRSukglYu0si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Training the Classification model\n",
        "#Takes in a List of Dataframes or a single dataframe to train the model\n",
        "\n",
        "def train_cluster_classification_model(  data, number_of_clusters ):\n",
        "\n",
        "  if 'ActivePT' in data.columns:\n",
        "    flag = 1\n",
        "  else:\n",
        "    flag = 0\n",
        "\n",
        "  labels = []\n",
        "  centers = []\n",
        "  if flag == 1:\n",
        "    X = np.array(data.drop(['ActivePT'], axis=1))\n",
        "  else:\n",
        "    X = np.array(data)\n",
        "\n",
        "  labels, _ = cluster_kmeans( X, number_of_clusters )\n",
        "\n",
        "  data['cluster_labels'] = labels\n",
        "\n",
        "  if flag == 1:\n",
        "    train_X = data.drop(['ActivePT','cluster_labels'], axis=1)\n",
        "    train_y = data['cluster_labels']\n",
        "  else:\n",
        "    train_X = data.drop(['cluster_labels'], axis=1)\n",
        "    train_y = data['cluster_labels']\n",
        "\n",
        "  model = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
        "  model.fit(train_X,train_y)\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "z5_f52q1pJaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Saving the Model\n",
        "# import pickle\n",
        "\n",
        "# filename = 'january_classification_model.sav'\n",
        "# pickle.dump(model, open(data_files_path + \"/\" + filename, 'wb'))"
      ],
      "metadata": {
        "id": "9GCISRznlZWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_week_of_month(year, month, day):\n",
        "    x = np.array(calendar.monthcalendar(year, month))\n",
        "    week_of_month = np.where(x==day)[0][0] + 1\n",
        "    return week_of_month\n",
        "\n",
        "\n",
        "def get_f1_score( data, model, num_clusters ):\n",
        "  prediction_labels = model.predict(data)\n",
        "  kmeans_labels, _ = cluster_kmeans(np.array(data), num_clusters)\n",
        "\n",
        "  if len(set(kmeans_labels)) > 1:\n",
        "    cluster_silScore  = metrics.silhouette_score(np.array(data), kmeans_labels, metric='euclidean')\n",
        "  else:\n",
        "    cluster_silScore = 0\n",
        "\n",
        "    \n",
        "  f1_score = metrics.f1_score(kmeans_labels, prediction_labels, average='micro' )\n",
        "\n",
        "  return f1_score, cluster_silScore"
      ],
      "metadata": {
        "id": "TJmB0os7tJPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on a week and Testing on week\n",
        "\n",
        "def predict_multiple_weeks( data, model, num_clusters ):\n",
        "\n",
        "  if 'ActivePT' in data.columns:\n",
        "    data = data.drop(['ActivePT'], axis=1)\n",
        "\n",
        "  # fixing the start date to Monday\n",
        "  start_date = data.index[0].date()\n",
        "  while( start_date.isoweekday() != 1 ):\n",
        "    start_date += timedelta(days=1)\n",
        "\n",
        "  # fixing the end date to Saturday\n",
        "  end_date = data.index[-1].date()\n",
        "  while( end_date.isoweekday() != 6 ):\n",
        "    end_date -= timedelta(days=1)\n",
        "\n",
        "  period = (end_date - start_date).days + 1\n",
        "  \n",
        "  week_list = []\n",
        "  f1_score_list = []\n",
        "  week_start_date = []\n",
        "  week_end_date = []\n",
        "  month_list = []\n",
        "\n",
        "  flag = 0\n",
        "  for dt in pd.date_range( start_date, periods = period ):\n",
        "\n",
        "    if flag == 0:\n",
        "      week_start = dt.date()\n",
        "      flag = 1\n",
        "\n",
        "    if dt.date().isoweekday() == 7 and flag == 1:\n",
        "      week_end = dt.date()\n",
        "      flag = 0\n",
        "      if week_start.month == week_end.month:\n",
        "        f1_score, clus_sil = get_f1_score( data.loc[str(week_start):str(week_end)], model, num_clusters)\n",
        "\n",
        "        f1_score, clus_sil = round(f1_score,4), round(clus_sil,4)\n",
        "\n",
        "        week_number = get_week_of_month(week_start.year, week_start.month, week_start.day)\n",
        "\n",
        "        week_list.append( str(week_start.strftime(\"%B\"))[:3] + '-week-' + str(week_number) )\n",
        "        week_start_date.append( str(week_start) )\n",
        "        week_end_date.append( str(week_end) )\n",
        "        f1_score_list.append(f1_score)\n",
        "        month_list.append(week_start.strftime(\"%B\"))\n",
        "\n",
        "  f1_score_df = pd.DataFrame( data={'Month_week': [], 'week_start_date': [], 'week_end_date': [], 'f1_score': [],\n",
        "                                    'Clustering Silhouette Score': [], 'month': []} )\n",
        "\n",
        "  f1_score_df['Month_week'] = week_list\n",
        "  f1_score_df['week_start_date'] = week_start_date\n",
        "  f1_score_df['week_end_date'] = week_end_date\n",
        "  f1_score_df['f1_score'] = f1_score_list\n",
        "  f1_score_df['Clustering Silhouette Score'] = clus_sil\n",
        "  f1_score_df['month'] = month_list\n",
        "\n",
        "  return f1_score_df\n"
      ],
      "metadata": {
        "id": "Wn_PURn5vmbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training on mondays of a month and Testing on mondaya of other months\n",
        "\n",
        "def predict_multiple_days( data, model, num_clusters, day_num ):\n",
        "\n",
        "  if 'ActivePT' in data.columns:\n",
        "    data = data.drop(['ActivePT'], axis=1)\n",
        "\n",
        "  start_date = data.index[0].date()\n",
        "  end_date = data.index[-1].date()\n",
        "\n",
        "  period = (end_date - start_date).days + 1\n",
        "\n",
        "  month_week_list = []\n",
        "  date_list = []\n",
        "  f1_score_list = []\n",
        "  clus_sil_list = []\n",
        "  month_list = []\n",
        "\n",
        "  for dt in pd.date_range( start_date, periods = period ):\n",
        "\n",
        "    curr_date = dt.date()\n",
        "  \n",
        "    if curr_date.isoweekday() == day_num:\n",
        "      \n",
        "      f1_score, clus_sil = get_f1_score( data.loc[str(curr_date)], model, num_clusters )\n",
        "\n",
        "      f1_score, clus_sil = round(f1_score,4), round(clus_sil,4)       \n",
        "\n",
        "      week_number = get_week_of_month( curr_date.year, curr_date.month, curr_date.day )\n",
        "\n",
        "      month_week_list.append( curr_date.strftime(\"%B\")[:3]+'-week-'+str(week_number) )\n",
        "      date_list.append(str(curr_date))\n",
        "      f1_score_list.append(f1_score)\n",
        "      clus_sil_list.append(clus_sil)\n",
        "      month_list.append(curr_date.strftime(\"%B\"))\n",
        "\n",
        "  f1_score_df = pd.DataFrame( data={'Month_week': [], 'date': [], 'f1_score': [], \n",
        "                                    'Clustering Silhouette Score': [], 'month': []} )\n",
        "\n",
        "  f1_score_df['Month_week'] = month_week_list\n",
        "  f1_score_df['date'] = date_list\n",
        "  f1_score_df['f1_score'] = f1_score_list\n",
        "  f1_score_df['Clustering Silhouette Score'] = clus_sil_list\n",
        "  f1_score_df['month'] = month_list\n",
        "\n",
        "  return f1_score_df\n"
      ],
      "metadata": {
        "id": "WGMdEnAQBQgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_on_multiple_weeks( data , num_clusters, start_week_Monday = True ):\n",
        "\n",
        "  if 'ActivePT' in data.columns:\n",
        "    data = data.drop(['ActivePT'], axis=1)\n",
        "\n",
        "  if start_week_Monday == True:\n",
        "    # fixing the start date to Monday\n",
        "    start_date = data.index[0].date()\n",
        "    while( start_date.isoweekday() != 1 ):\n",
        "      start_date += timedelta(days=1)\n",
        "\n",
        "    # fixing the end date to Saturday\n",
        "    end_date = data.index[-1].date()\n",
        "    while( end_date.isoweekday() != 7 ):\n",
        "      end_date -= timedelta(days=1)\n",
        "\n",
        "    period = (end_date - start_date).days + 1\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    flag = 0\n",
        "    for dt in pd.date_range( start_date, periods = period ):\n",
        "\n",
        "      if flag == 0:\n",
        "        week_start = dt.date()\n",
        "        flag = 1\n",
        "\n",
        "      if dt.date().isoweekday() == 7 and flag == 1:\n",
        "        print(dt.date())\n",
        "        week_end = dt.date()\n",
        "        flag = 0\n",
        "        if week_start.month == week_end.month:\n",
        "          print(week_start, week_end)\n",
        "          df_list.append( data.loc[ str(week_start) : str(week_end) ] )\n",
        "\n",
        "    if len(df_list) == 0:\n",
        "      return None\n",
        "\n",
        "    train_df = pd.concat(df_list)\n",
        "  else:\n",
        "    train_df = data\n",
        "\n",
        "  model = train_cluster_classification_model( train_df, num_clusters )\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "yM83jhRi0vIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_on_multiple_days( data, number_of_clusters, day_num ):\n",
        "\n",
        "  if 'ActivePT' in data.columns:\n",
        "    data = data.drop(['ActivePT'], axis=1)\n",
        "\n",
        "  flag = 0\n",
        "  start_date = data.index[0].date()\n",
        "  end_date = data.index[-1].date()\n",
        "\n",
        "  period = (end_date - start_date).days + 1\n",
        "\n",
        "  df_list = []\n",
        "  flag = 0\n",
        "  for dt in pd.date_range( start_date, periods = period ):\n",
        "    curr_date = dt.date()\n",
        "\n",
        "    if curr_date.isoweekday() == day_num:\n",
        "      if flag == 0:\n",
        "        print(\"Training on\",curr_date.strftime(\"%B\"),curr_date.strftime(\"%A\")+\"s\" )\n",
        "        flag = 1\n",
        "      df_list.append( data.loc[str(curr_date)] )\n",
        "\n",
        "  train_df = pd.concat(df_list)\n",
        "  model = train_cluster_classification_model( train_df, number_of_clusters )\n",
        "  return model"
      ],
      "metadata": {
        "id": "lwxCvUJ7MMrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def week_train( data, num_clusters, test_on = 'week', day = 1, all_weeks = False, save_graphs = True ):\n",
        "\n",
        "  days=[\"Monday\", \"Tuesday\", \"Wednesday\" ,\"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "\n",
        "  if test_on != 'week':\n",
        "    print('Testing on',days[day-1]+'s')\n",
        "\n",
        "  fig,ax = plt.subplots(figsize=(15,3))\n",
        "  ax.set(ylim=(0, 1))\n",
        "\n",
        "  if all_weeks == False:\n",
        "    if test_on == 'week':\n",
        "      folder_name = 'train_one_week/test_one_week'\n",
        "    else:\n",
        "      folder_name = 'train_one_week/test_'+days[day-1]\n",
        "  else:\n",
        "    if test_on == 'week':\n",
        "      folder_name = 'train_all_weeks/test_one_week'\n",
        "    else:\n",
        "      folder_name = 'train_all_weeks/test_'+days[day-1]\n",
        "\n",
        "\n",
        "  if os.path.exists( data_files_path + '/results/' + folder_name ) == False:\n",
        "    os.makedirs( data_files_path + '/results/' + folder_name )\n",
        "\n",
        "  month_palette = {\n",
        "      'January': list(sns.color_palette())[0],\n",
        "      'February': list(sns.color_palette())[1],\n",
        "      'March': list(sns.color_palette())[2],\n",
        "      'April': list(sns.color_palette())[3],\n",
        "      'May': list(sns.color_palette())[4],\n",
        "      'June': list(sns.color_palette())[5],\n",
        "  }\n",
        "\n",
        "  markers = {\n",
        "      'January': 'o',\n",
        "      'February': 'x',\n",
        "      'March': '^',\n",
        "      'April': '+',\n",
        "      'May': 's',\n",
        "      'June': 'D',\n",
        "  } #['o', 'x', '^', '+', '*', '8', 's', 'p', 'D', 'V']\n",
        "\n",
        "  training_weeks = {\n",
        "      'January': ['2022-01-10','2022-01-16'],\n",
        "      'February': ['2022-02-14','2022-02-20'],\n",
        "      'March': ['2022-03-07','2022-03-13'],\n",
        "      'April': ['2022-04-11','2022-04-17'],\n",
        "      'May': ['2022-05-16','2022-05-22'],\n",
        "      'June': ['2022-06-06','2022-06-12'],\n",
        "  }\n",
        "\n",
        "  marker_plot = []\n",
        "\n",
        "  for month in sorted(list(set([str(i) for i in data.index.to_period('M')]))):\n",
        "    month_name = datetime.strptime(month, '%Y-%m').strftime(\"%B\")\n",
        "    print(\"Genrating Scores for\", month_name)\n",
        "\n",
        "    if all_weeks == False:\n",
        "      model = train_cluster_classification_model( data.loc[ training_weeks[month_name][0]:training_weeks[month_name][1] ], num_clusters )\n",
        "    else:\n",
        "      model = train_on_multiple_weeks( data.loc[month], num_clusters )\n",
        "\n",
        "\n",
        "    if test_on == 'week':\n",
        "      f1_score_df = predict_multiple_weeks( data.loc[month:], model, num_clusters )\n",
        "    else:\n",
        "      f1_score_df = predict_multiple_days( data.loc[month:], model, num_clusters, day )\n",
        "\n",
        "    with open( os.path.join(data_files_path,'results',folder_name,month_name+'.csv'), 'w', encoding = 'utf-8-sig') as f:\n",
        "      f1_score_df.to_csv(f)\n",
        "\n",
        "    if save_graphs == True:\n",
        "      fig2,ax2 = plt.subplots(figsize=(15,3))\n",
        "      ax2.set(ylim=(0, 1))\n",
        "      sns.lineplot( data=f1_score_df, x='Month_week', y='f1_score', c='black', alpha=0.1, ax=ax2 )\n",
        "      sns.scatterplot( data=f1_score_df, x='Month_week', y='f1_score', s=50, ax=ax2)\n",
        "      if all_weeks == False and test_on ==  'week':\n",
        "        sns.scatterplot( data=f1_score_df.loc[ f1_score_df['week_start_date'] == training_weeks[month_name][0] ], \n",
        "                        x='Month_week', y='f1_score', color='none', edgecolor='red', s=150, ax=ax2 )\n",
        "      plt.xticks(rotation=45)\n",
        "\n",
        "      if all_weeks == False:\n",
        "        ax2.set_title(\"F1 Scores using Trained Model on one week of \"+month_name+\" Testing on \"+days[day-1]).set_fontsize(15)\n",
        "      else:\n",
        "        ax2.set_title(\"F1 Scores using Trained Model on all week of \"+month_name+\" Testing on \"+days[day-1]).set_fontsize(15)\n",
        "\n",
        "      if save_graphs == True:\n",
        "        fig2.savefig(os.path.join(data_files_path,'results',folder_name,month_name+'.png'), bbox_inches='tight', dpi=800)\n",
        "      fig2.clf()\n",
        "      plt.close(fig2)\n",
        "\n",
        "    sns.lineplot( data=f1_score_df, x='Month_week', y='f1_score', c='black', alpha=0.1, ax=ax )\n",
        "    sns.scatterplot( data=f1_score_df, x='Month_week', y='f1_score', s=50, marker = markers[month_name], ax=ax)\n",
        "    if all_weeks == False and test_on ==  'week':\n",
        "      sns.scatterplot( data=f1_score_df.loc[ f1_score_df['week_start_date'] == training_weeks[month_name][0] ],\n",
        "                      x='Month_week', y='f1_score', color='none', edgecolor='red', s=150, ax=ax )\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "    marker_plot.append( mlines.Line2D([], [], color=month_palette[month_name], marker=markers[month_name], linestyle='None',markersize=10, label=month_name ))\n",
        "    \n",
        "\n",
        "  ax.legend(handles=marker_plot, bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0)\n",
        "  if all_weeks == False:\n",
        "    if test_on == 'week':\n",
        "      ax.set_title(\"F1 Scores using Trained Model on one week Testing on one week\").set_fontsize(15)\n",
        "    else:\n",
        "      ax.set_title(\"F1 Scores using Trained Model on one week Testing on \"+days[day-1]).set_fontsize(15)\n",
        "  else:\n",
        "    if test_on == 'week':\n",
        "      ax.set_title(\"F1 Scores using Trained Model on all weeks Testing on one week\").set_fontsize(15)\n",
        "    else:\n",
        "      ax.set_title(\"F1 Scores using Trained Model on all weeks Testing on \"+days[day-1]).set_fontsize(15)\n",
        "  if save_graphs == True:\n",
        "    fig.savefig(os.path.join(data_files_path,'results',folder_name,'all_months.png'), bbox_inches='tight', dpi=800)\n",
        "  fig.clf()\n",
        "  plt.close(fig)\n",
        "\n",
        "  del f1_score_df\n",
        "  del data"
      ],
      "metadata": {
        "id": "Y0eABozWzzZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def day_train( data, num_clusters, train_day = 1, test_day = None, save_graphs = True ):\n",
        "\n",
        "  if test_day == None:\n",
        "    test_day = train_day\n",
        "\n",
        "  days=[\"Monday\", \"Tuesday\", \"Wednesday\" ,\"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "\n",
        "  print('Testing on',days[train_day-1]+'s')\n",
        "\n",
        "  fig,ax = plt.subplots(figsize=(15,3))\n",
        "  ax.set(ylim=(0, 1))\n",
        "\n",
        "  train_folder_name = 'train_'+days[train_day-1]\n",
        "  test_folder_name = 'test_'+days[test_day-1]\n",
        "\n",
        "  if os.path.exists( os.path.join( data_files_path,'results', train_folder_name, test_folder_name ) ) == False:\n",
        "    os.makedirs( os.path.join( data_files_path,'results', train_folder_name, test_folder_name ) )\n",
        "\n",
        "  month_palette = {\n",
        "      'January': list(sns.color_palette())[0],\n",
        "      'February': list(sns.color_palette())[1],\n",
        "      'March': list(sns.color_palette())[2],\n",
        "      'April': list(sns.color_palette())[3],\n",
        "      'May': list(sns.color_palette())[4],\n",
        "      'June': list(sns.color_palette())[5],\n",
        "  }\n",
        "\n",
        "  markers = {\n",
        "      'January': 'o',\n",
        "      'February': 'x',\n",
        "      'March': '^',\n",
        "      'April': '+',\n",
        "      'May': 's',\n",
        "      'June': 'D',\n",
        "  } #['o', 'x', '^', '+', '*', '8', 's', 'p', 'D', 'V']\n",
        "\n",
        "  marker_plot = []\n",
        "\n",
        "  for month in sorted(list(set([str(i) for i in data.index.to_period('M')]))):\n",
        "    month_name = datetime.strptime(month, '%Y-%m').strftime(\"%B\")\n",
        "\n",
        "    print(\"Genrating Scores for\", month_name)\n",
        "    model = train_on_multiple_days( data.loc[month], num_clusters, train_day ) #(1 for Monday, #7 for Sundays)\n",
        "    f1_score_df = predict_multiple_days( data.loc[month:], model, num_clusters, test_day ) #(1 for Monday, #7 for Sundays)\n",
        "\n",
        "    with open( os.path.join( data_files_path,'results', train_folder_name, test_folder_name, month_name +'.csv' ), 'w', encoding = 'utf-8-sig') as f:\n",
        "      f1_score_df.to_csv(f)\n",
        "\n",
        "    fig2,ax2 = plt.subplots(figsize=(15,3))\n",
        "    sns.lineplot( data=f1_score_df, x='Month_week', y='f1_score', c='black', alpha=0.1, ax=ax2 )\n",
        "    sns.scatterplot( data=f1_score_df, x='Month_week', y='f1_score', s=50, palette = month_palette, ax=ax2)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # ax2.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0)\n",
        "    ax2.set_title(f\"F1 Scores using Trained Model on {month_name} {days[train_day-1]}s Testing on {days[test_day-1]}\").set_fontsize(15)\n",
        "    \n",
        "    if save_graphs == True:\n",
        "      fig2.savefig( os.path.join( data_files_path,'results', train_folder_name, test_folder_name, month_name +'.png' ), bbox_inches='tight', dpi=1200)\n",
        "    fig2.clf()\n",
        "    plt.close(fig2)\n",
        "\n",
        "\n",
        "    sns.lineplot( data=f1_score_df, x='Month_week', y='f1_score', c='black', alpha=0.1, ax=ax )\n",
        "    sns.scatterplot( data=f1_score_df, x='Month_week', y='f1_score', s=50, palette = month_palette, marker = markers[month_name], ax=ax)\n",
        "    marker_plot.append( mlines.Line2D([], [], color=month_palette[month_name], marker=markers[month_name], linestyle='None',markersize=10, label=month_name ))\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "  ax.legend(handles=marker_plot, bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0)\n",
        "  ax.set_title(f\"F1 Scores using Trained Model on {days[train_day-1]} Testing on {days[test_day-1]}\").set_fontsize(15)\n",
        "  \n",
        "  if save_graphs == True:\n",
        "    fig.savefig(os.path.join( data_files_path,'results', train_folder_name, test_folder_name, 'all_months' +'.png' ), bbox_inches='tight', dpi=1200)\n",
        "  fig.clf()\n",
        "  plt.close(fig)\n",
        "  \n",
        "  del f1_score_df\n",
        "  del data"
      ],
      "metadata": {
        "id": "XlTiHs4oOgbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dates_in_dataframe = set([])\n",
        "for i in df_merged_filled.index:\n",
        "  if i.date() not in dates_in_dataframe:\n",
        "    dates_in_dataframe.add(i.date())\n",
        "dates_in_dataframe = sorted(list(dates_in_dataframe))"
      ],
      "metadata": {
        "id": "HIIBxlD37hH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged_filled.index[0], df_merged_filled.index[-1]"
      ],
      "metadata": {
        "id": "JpXYNv13E6mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_start = f'{dates_in_dataframe[0].year}-{dates_in_dataframe[0].month}-{dates_in_dataframe[0].day}'\n",
        "train_end = f'{dates_in_dataframe[6].year}-{dates_in_dataframe[6].month}-{dates_in_dataframe[6].day}'"
      ],
      "metadata": {
        "id": "Ot-4zo1S8dT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_on_multiple_weeks(df_merged_filled.loc[train_start:train_end], num_clusters=6, start_week_Monday=False)"
      ],
      "metadata": {
        "id": "2gPVmwJ9mOm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for date_item in dates_in_dataframe[7:]:\n",
        "  date = f'{date_item.year}-{date_item.month}-{date_item.day}'\n",
        "  test_df = df_merged_filled.loc[date]\n",
        "  prediction_labels = model.predict(test_df.drop(['ActivePT'], axis=1))\n",
        "  fig, ax = plt.subplots(2,1, figsize=(12,5))\n",
        "\n",
        "\n",
        "  principalDf = pca_function(test_df, 2)\n",
        "\n",
        "  sns.scatterplot(data=test_df, x=test_df.index, y='ActivePT', hue=prediction_labels, palette = palette, ax=ax[0])\n",
        "  sns.scatterplot( data = principalDf, x=\"components_1\", y=\"components_2\", hue=prediction_labels, palette=palette,ax = ax[1])\n",
        "\n",
        "\n",
        "  # prediction_silScore  = metrics.silhouette_score(np.array(test_df.drop(['ActivePT'], axis=1)), prediction_labels, metric='euclidean')\n",
        "  # cluster_silScore  = metrics.silhouette_score(np.array(test_df.drop(['ActivePT'], axis=1)), test_df['labels_KMEANS'], metric='euclidean')\n",
        "  # f1_score = metrics.f1_score(test_df['labels_KMEANS'], prediction_labels, average='micro' )\n",
        "\n",
        "  ax[0].legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0)\n",
        "  ax[1].legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0)\n",
        "\n",
        "  ax[0].set_title('(a) Cluster with Active Power on Y-Axis').set_fontsize(15)\n",
        "  ax[0].set_xlabel('datetime')\n",
        "  ax[1].set_title('(b) PCA ').set_fontsize(15)\n",
        "\n",
        "  fig.tight_layout()\n",
        "  fig.savefig(f'{Location}_{date}')\n"
      ],
      "metadata": {
        "id": "k9738RTvmj6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %rm -rf figs"
      ],
      "metadata": {
        "id": "BXLX-fIX-_Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir figs"
      ],
      "metadata": {
        "id": "LWtpTpZ1_WfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mv *.png figs/"
      ],
      "metadata": {
        "id": "H7ez52BWI-6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r figs.zip figs/"
      ],
      "metadata": {
        "id": "CWjJi8Dn-BbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}